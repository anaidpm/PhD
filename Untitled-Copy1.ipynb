{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mechanicalsoup in c:\\python34\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: requests>=2.0 in c:\\python34\\lib\\site-packages (from mechanicalsoup) (2.19.1)\n",
      "Requirement already satisfied: six>=1.4 in c:\\python34\\lib\\site-packages (from mechanicalsoup) (1.10.0)\n",
      "Requirement already satisfied: lxml in c:\\python34\\lib\\site-packages (from mechanicalsoup) (4.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python34\\lib\\site-packages (from mechanicalsoup) (4.6.0)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in c:\\python34\\lib\\site-packages (from requests>=2.0->mechanicalsoup) (2.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\python34\\lib\\site-packages (from requests>=2.0->mechanicalsoup) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in c:\\python34\\lib\\site-packages (from requests>=2.0->mechanicalsoup) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python34\\lib\\site-packages (from requests>=2.0->mechanicalsoup) (2018.4.16)\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install mechanicalsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, you can install BeautifulSoup\n",
    "# https://pypi.python.org/pypi/beautifulsoup4\n",
    "\n",
    "# Or download the file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import mechanicalsoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.sciencedirect.com/search?qs=tuberculosis%20case%20report&show=25&sortBy=relevance'\n",
    "numArticle=1\n",
    "while url:\n",
    "    print(\">>>>>> Retrieving URL: %s\" % url)\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    articles=soup.find_all(\"div\", {\"class\": \"result-item-content\"})\n",
    "    for a in articles:\n",
    "        title= a.find('h2')\n",
    "        pii=a.find('a').get('href', None)\n",
    "        pii=pii[-17:]\n",
    "        print(\"\\nArticle #\"+str(numArticle)+\": \"+title.text)\n",
    "          \n",
    "        numArticle=numArticle+1\n",
    "        \n",
    "        if title.text.find!=-1: #if title contains \"case\"\n",
    "            #open article URL\n",
    "            u=\"https://api.elsevier.com/content/article/pii/\"+pii+\"?apiKey=444438d929e036b98383ca350673128c\"\n",
    "            h = urllib.request.urlopen(u).read()\n",
    "            s = BeautifulSoup(h, 'html.parser')\n",
    "            #print(s)\n",
    "            found=s.find(\"body\")\n",
    "            #case=case.find_all(\"section\")\n",
    "            if found:\n",
    "                case=found.find(\"ce:sections\").find_all(\"ce:section\")\n",
    "                if (case):\n",
    "                    print(case[0])\n",
    "                else:\n",
    "                    print(\"No case\")\n",
    "            else:\n",
    "                print(\"No access\")\n",
    "    print (\"Load next (Y/N)?\")\n",
    "    ans = input('--> ')\n",
    "\n",
    "    if (ans == \"y\" or ans == \"Y\"):\n",
    "        #then go to next page\n",
    "        url=soup.find(\"li\",{\"class\":\"pagination-link next-link\"})\n",
    "        if url:\n",
    "            url=url.find('a').get('href', None)\n",
    "            url='https://www.sciencedirect.com/search'+url\n",
    "    else:\n",
    "        url=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I SUUUUUUUUUUUUUUUUUUUUUUUCK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
